{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Data Quality Monitoring\n",
    "**Objective**: Use Great Expectations to perform data profiling and write validation rules.\n",
    "\n",
    "1. Data Profiling with Great Expectations\n",
    "\n",
    "### Profile a JSON dataset with product sales data to check for null values in the 'ProductID' and 'Price' fields.\n",
    "- Create an expectation suite and connect it to the data context.\n",
    "- Use the `expect_column_values_to_not_be_null` expectation to profile these fields.\n",
    "- Review the summary to identify any unexpected null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EphemeralDataContext' object has no attribute 'add_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Add a JSON datasource if it doesn't exist\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datasource_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m context\u001b[38;5;241m.\u001b[39mlist_datasources()]:\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_json\u001b[49m(\n\u001b[1;32m     32\u001b[0m         name\u001b[38;5;241m=\u001b[39mdatasource_name,\n\u001b[1;32m     33\u001b[0m         base_directory\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(json_file_path)),\n\u001b[1;32m     34\u001b[0m         batching_regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(.+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Create a BatchRequest to load the JSON data\u001b[39;00m\n\u001b[1;32m     38\u001b[0m batch_request \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mget_batch_request(\n\u001b[1;32m     39\u001b[0m     datasource_name\u001b[38;5;241m=\u001b[39mdatasource_name,\n\u001b[1;32m     40\u001b[0m     data_connector_name\u001b[38;5;241m=\u001b[39mdata_connector_name,\n\u001b[1;32m     41\u001b[0m     data_asset_name\u001b[38;5;241m=\u001b[39mdata_asset_name,\n\u001b[1;32m     42\u001b[0m     batch_spec_passthrough\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreader_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     43\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EphemeralDataContext' object has no attribute 'add_json'"
     ]
    }
   ],
   "source": [
    "# write your code from here\n",
    "\n",
    "import great_expectations as gx\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize Great Expectations context\n",
    "context = gx.get_context()\n",
    "\n",
    "# Create a sample JSON dataset for product sales data\n",
    "json_data = [\n",
    "    {\"ProductID\": \"PROD101\", \"ProductName\": \"Laptop\", \"Price\": 1200.00, \"QuantitySold\": 10},\n",
    "    {\"ProductID\": None, \"ProductName\": \"Mouse\", \"Price\": 25.00, \"QuantitySold\": 50},\n",
    "    {\"ProductID\": \"PROD104\", \"ProductName\": \"Keyboard\", \"Price\": 75.00, \"QuantitySold\": 30},\n",
    "    {\"ProductID\": \"PROD105\", \"ProductName\": \"Monitor\", \"Price\": None, \"QuantitySold\": 15},\n",
    "    {\"ProductID\": \"PROD106\", \"ProductName\": \"Webcam\", \"Price\": 50.00, \"QuantitySold\": 25},\n",
    "]\n",
    "\n",
    "# Save the JSON data to a file\n",
    "json_file_path = 'product_sales.json'\n",
    "with open(json_file_path, 'w') as f:\n",
    "    import json\n",
    "    json.dump(json_data, f)\n",
    "\n",
    "# Define datasource parameters for JSON\n",
    "datasource_name = 'product_json_datasource'\n",
    "data_connector_name = 'default_inferred_data_connector_name'\n",
    "data_asset_name = 'product_sales_data'\n",
    "\n",
    "# Add a JSON datasource if it doesn't exist\n",
    "if datasource_name not in [ds['name'] for ds in context.list_datasources()]:\n",
    "    context.add_pandas_json_datasource(\n",
    "        name=datasource_name,\n",
    "        base_directory=os.path.dirname(os.path.abspath(json_file_path)),\n",
    "        batching_regex=r\"(.+)\\.json\",\n",
    "    )\n",
    "\n",
    "# Create a BatchRequest to load the JSON data\n",
    "batch_request = context.get_batch_request(\n",
    "    datasource_name=datasource_name,\n",
    "    data_connector_name='default_inferred_data_connector_name',\n",
    "    data_asset_name='product_sales.json',\n",
    ")\n",
    "\n",
    "# Create an Expectation Suite for profiling null values\n",
    "expectation_suite_name = 'product_sales_null_profiling'\n",
    "try:\n",
    "    suite = context.suites.get(expectation_suite_name)\n",
    "    print(f\"Loaded existing Expectation Suite: {expectation_suite_name}\")\n",
    "except gx.exceptions.ExpectationSuiteNotFoundError:\n",
    "    suite = context.create_expectation_suite(\n",
    "        expectation_suite_name=expectation_suite_name, overwrite_existing=True\n",
    "    )\n",
    "    print(f\"Created Expectation Suite: {expectation_suite_name}\")\n",
    "\n",
    "# Create a validator\n",
    "validator = context.get_validator(\n",
    "    batch_request=batch_request,\n",
    "    expectation_suite=suite,\n",
    ")\n",
    "print(f\"Using validator for data asset: {validator.active_batch_request.data_asset_name}\")\n",
    "\n",
    "# Profile for null values in 'ProductID'\n",
    "validator.expect_column_values_to_not_be_null(column='ProductID')\n",
    "\n",
    "# Profile for null values in 'Price'\n",
    "validator.expect_column_values_to_not_be_null(column='Price')\n",
    "\n",
    "# Save the expectation suite with the profiling expectations\n",
    "validator.save_expectation_suite()\n",
    "print(f\"Saved Expectation Suite: {expectation_suite_name}\")\n",
    "\n",
    "# Run the validation (which acts as our profiling run in this case)\n",
    "validation_result = validator.validate()\n",
    "\n",
    "print(\"\\nValidation Results (Summary of Null Values):\\n\")\n",
    "for result in validation_result['results']:\n",
    "    if result['expectation_config']['expectation_type'] == 'expect_column_values_to_not_be_null':\n",
    "        column_name = result['expectation_config']['kwargs']['column']\n",
    "        success = result['success']\n",
    "        if not success:\n",
    "            unexpected_count = result['result']['unexpected_count']\n",
    "            print(f\"Column '{column_name}': Found {unexpected_count} null values.\")\n",
    "        else:\n",
    "            print(f\"Column '{column_name}': No null values found.\")\n",
    "\n",
    "# Build Data Docs to view the full validation results\n",
    "context.build_data_docs(validation_result_list=[validation_result])\n",
    "print(f\"\\nData Docs generated. Check 'great_expectations/uncommitted/data_docs/local_site/index.html' for detailed profiling.\")\n",
    "\n",
    "# Clean up the sample JSON file\n",
    "os.remove(json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Writing Validation Rules for Data Ingestion\n",
    "\n",
    "### Define validation rules for an API data source to confirm that 'Status' field contains only predefined statuses ('Active', 'Inactive').\n",
    "\n",
    "- Apply `expect_column_values_to_be_in_set` to check field values during data ingestion.\n",
    "- Execute the validation and review any mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
