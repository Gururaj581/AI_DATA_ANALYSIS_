{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Profiling Techniques Examples\n",
    "\n",
    "# 1. Descriptive Statistics:\n",
    "# Task 1: Calculate the mean, median, and mode for sales figures in a retail dataset.\n",
    "# Task 2: Analyze the average age, median, and mode in a customer demographic\n",
    "# dataset.\n",
    "# Task 3: Determine the mean, median, and mode of daily website visit counts.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sample retail sales data (in dollars)\n",
    "sales_data = [\n",
    "    120, 145, 135, 210, 195, 165, 170, 155, 190, 230,\n",
    "    145, 165, 175, 185, 205, 225, 140, 160, 150, 180,\n",
    "    190, 200, 185, 170, 190, 210, 235, 180, 175, 165\n",
    "]\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "df = pd.DataFrame({'Sales': sales_data})\n",
    "\n",
    "# 1. Basic Descriptive Statistics\n",
    "print(\"===== BASIC DESCRIPTIVE STATISTICS =====\")\n",
    "print(f\"Count: {len(sales_data)}\")\n",
    "print(f\"Min: ${min(sales_data)}\")\n",
    "print(f\"Max: ${max(sales_data)}\")\n",
    "print(f\"Range: ${max(sales_data) - min(sales_data)}\")\n",
    "print(f\"Sum: ${sum(sales_data)}\")\n",
    "\n",
    "# 2. Mean, Median, Mode Calculation\n",
    "# Method 1: Using basic Python\n",
    "mean_sales = sum(sales_data) / len(sales_data)\n",
    "sorted_sales = sorted(sales_data)\n",
    "mid = len(sorted_sales) // 2\n",
    "# If even number of elements, average the two middle values\n",
    "if len(sorted_sales) % 2 == 0:\n",
    "    median_sales = (sorted_sales[mid-1] + sorted_sales[mid]) / 2\n",
    "else:\n",
    "    median_sales = sorted_sales[mid]\n",
    "\n",
    "# Finding mode using a frequency counter\n",
    "from collections import Counter\n",
    "sales_counter = Counter(sales_data)\n",
    "mode_sales = sales_counter.most_common(1)[0][0]\n",
    "mode_count = sales_counter.most_common(1)[0][1]\n",
    "\n",
    "print(\"\\n===== MANUAL CALCULATION =====\")\n",
    "print(f\"Mean: ${mean_sales:.2f}\")\n",
    "print(f\"Median: ${median_sales:.2f}\")\n",
    "print(f\"Mode: ${mode_sales} (appears {mode_count} times)\")\n",
    "\n",
    "# Method 2: Using NumPy and SciPy\n",
    "np_mean = np.mean(sales_data)\n",
    "np_median = np.median(sales_data)\n",
    "mode_result = stats.mode(sales_data)\n",
    "# Handle both older and newer versions of scipy\n",
    "try:\n",
    "    # For newer scipy versions where mode() returns scalar values when input is 1D\n",
    "    np_mode = mode_result.mode\n",
    "    np_mode_count = mode_result.count\n",
    "except (IndexError, AttributeError):\n",
    "    # For older scipy versions where mode returns arrays\n",
    "    np_mode = mode_result.mode[0]\n",
    "    np_mode_count = mode_result.count[0]\n",
    "\n",
    "print(\"\\n===== NUMPY/SCIPY CALCULATION =====\")\n",
    "print(f\"Mean: ${np_mean:.2f}\")\n",
    "print(f\"Median: ${np_median:.2f}\")\n",
    "print(f\"Mode: ${np_mode} (appears {np_mode_count} times)\")\n",
    "\n",
    "# Method 3: Using Pandas\n",
    "print(\"\\n===== PANDAS CALCULATION =====\")\n",
    "print(df['Sales'].describe())\n",
    "print(f\"Mode: ${df['Sales'].mode()[0]}\")\n",
    "\n",
    "# 3. Visual Analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(sales_data, bins=10, edgecolor='black')\n",
    "plt.axvline(np_mean, color='r', linestyle='dashed', linewidth=1, label=f'Mean: ${np_mean:.2f}')\n",
    "plt.axvline(np_median, color='g', linestyle='dashed', linewidth=1, label=f'Median: ${np_median:.2f}')\n",
    "plt.axvline(np_mode, color='b', linestyle='dashed', linewidth=1, label=f'Mode: ${np_mode}')\n",
    "plt.title('Sales Distribution')\n",
    "plt.xlabel('Sales Amount ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Box Plot\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.boxplot(sales_data, patch_artist=True)\n",
    "plt.title('Sales Box Plot')\n",
    "plt.ylabel('Sales Amount ($)')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Density Plot (KDE)\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.kdeplot(sales_data, fill=True)\n",
    "plt.axvline(np_mean, color='r', linestyle='dashed', linewidth=1, label=f'Mean: ${np_mean:.2f}')\n",
    "plt.axvline(np_median, color='g', linestyle='dashed', linewidth=1, label=f'Median: ${np_median:.2f}')\n",
    "plt.axvline(np_mode, color='b', linestyle='dashed', linewidth=1, label=f'Mode: ${np_mode}')\n",
    "plt.title('Sales Density Plot')\n",
    "plt.xlabel('Sales Amount ($)')\n",
    "plt.legend()\n",
    "\n",
    "# QQ Plot to check for normality\n",
    "plt.subplot(2, 2, 4)\n",
    "stats.probplot(sales_data, plot=plt)\n",
    "plt.title('QQ Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sales_analysis.png')\n",
    "plt.show()\n",
    "\n",
    "# 4. Additional Insights\n",
    "print(\"\\n===== ADDITIONAL STATISTICS =====\")\n",
    "print(f\"Standard Deviation: ${np.std(sales_data, ddof=1):.2f}\")\n",
    "print(f\"Variance: ${np.var(sales_data, ddof=1):.2f}\")\n",
    "print(f\"Skewness: {stats.skew(sales_data):.4f}\")\n",
    "print(f\"Kurtosis: {stats.kurtosis(sales_data):.4f}\")\n",
    "\n",
    "# 5. Percentiles\n",
    "print(\"\\n===== PERCENTILES =====\")\n",
    "print(f\"25th Percentile (Q1): ${np.percentile(sales_data, 25):.2f}\")\n",
    "print(f\"50th Percentile (Median): ${np.percentile(sales_data, 50):.2f}\")\n",
    "print(f\"75th Percentile (Q3): ${np.percentile(sales_data, 75):.2f}\")\n",
    "print(f\"IQR (Interquartile Range): ${np.percentile(sales_data, 75) - np.percentile(sales_data, 25):.2f}\")\n",
    "\n",
    "# 6. Identification of Outliers using IQR method\n",
    "Q1 = np.percentile(sales_data, 25)\n",
    "Q3 = np.percentile(sales_data, 75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers = [x for x in sales_data if x < lower_bound or x > upper_bound]\n",
    "\n",
    "print(\"\\n===== OUTLIER DETECTION =====\")\n",
    "print(f\"Lower Bound: ${lower_bound:.2f}\")\n",
    "print(f\"Upper Bound: ${upper_bound:.2f}\")\n",
    "if outliers:\n",
    "    print(f\"Outliers: {outliers}\")\n",
    "else:\n",
    "    print(\"No outliers detected\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "\n",
    "# Sample customer demographic data (ages)\n",
    "customer_ages = [\n",
    "    22, 35, 28, 42, 55, 38, 41, 32, 45, 29,\n",
    "    31, 48, 52, 33, 27, 39, 44, 36, 29, 51,\n",
    "    43, 38, 35, 47, 56, 34, 29, 41, 33, 38,\n",
    "    42, 50, 31, 29, 45, 37, 39, 32, 44, 53,\n",
    "    28, 36, 41, 47, 33, 38, 30, 49, 35, 42\n",
    "]\n",
    "\n",
    "# Create DataFrame for better analysis\n",
    "customers_df = pd.DataFrame({'Age': customer_ages})\n",
    "\n",
    "# 1. Basic Information\n",
    "print(\"===== CUSTOMER AGE DATA SUMMARY =====\")\n",
    "print(f\"Number of customers: {len(customer_ages)}\")\n",
    "print(f\"Youngest customer: {min(customer_ages)} years old\")\n",
    "print(f\"Oldest customer: {max(customer_ages)} years old\")\n",
    "print(f\"Age range: {max(customer_ages) - min(customer_ages)} years\")\n",
    "\n",
    "# 2. Mean, Median, Mode Calculation using different methods\n",
    "\n",
    "# Method 1: Manual calculation\n",
    "mean_age = sum(customer_ages) / len(customer_ages)\n",
    "sorted_ages = sorted(customer_ages)\n",
    "n = len(sorted_ages)\n",
    "if n % 2 == 0:\n",
    "    median_age = (sorted_ages[n//2 - 1] + sorted_ages[n//2]) / 2\n",
    "else:\n",
    "    median_age = sorted_ages[n//2]\n",
    "\n",
    "# Finding mode manually\n",
    "age_counter = Counter(customer_ages)\n",
    "mode_age = age_counter.most_common(1)[0][0]\n",
    "mode_count = age_counter.most_common(1)[0][1]\n",
    "\n",
    "print(\"\\n===== MANUAL CALCULATION =====\")\n",
    "print(f\"Mean age: {mean_age:.2f} years\")\n",
    "print(f\"Median age: {median_age:.2f} years\")\n",
    "print(f\"Mode age: {mode_age} years (appears {mode_count} times)\")\n",
    "\n",
    "# Method 2: Using NumPy and SciPy\n",
    "np_mean = np.mean(customer_ages)\n",
    "np_median = np.median(customer_ages)\n",
    "mode_result = stats.mode(customer_ages)\n",
    "# Handle both older and newer versions of scipy\n",
    "try:\n",
    "    # For newer scipy versions where mode() returns scalar values when input is 1D\n",
    "    np_mode = mode_result.mode\n",
    "    np_mode_count = mode_result.count\n",
    "except (IndexError, AttributeError):\n",
    "    # For older scipy versions where mode returns arrays\n",
    "    np_mode = mode_result.mode[0]\n",
    "    np_mode_count = mode_result.count[0]\n",
    "\n",
    "print(\"\\n===== NUMPY/SCIPY CALCULATION =====\")\n",
    "print(f\"Mean age: {np_mean:.2f} years\")\n",
    "print(f\"Median age: {np_median:.2f} years\")\n",
    "print(f\"Mode age: {np_mode} years (appears {np_mode_count} times)\")\n",
    "\n",
    "# Method 3: Using Pandas\n",
    "print(\"\\n===== PANDAS CALCULATION =====\")\n",
    "print(customers_df['Age'].describe())\n",
    "print(f\"Mode: {customers_df['Age'].mode()[0]} years\")\n",
    "\n",
    "# 3. Age distribution analysis by grouping\n",
    "# Group customers into age brackets\n",
    "age_brackets = {\n",
    "    '18-25': 0,\n",
    "    '26-35': 0,\n",
    "    '36-45': 0,\n",
    "    '46-55': 0,\n",
    "    '56+': 0\n",
    "}\n",
    "\n",
    "for age in customer_ages:\n",
    "    if 18 <= age <= 25:\n",
    "        age_brackets['18-25'] += 1\n",
    "    elif 26 <= age <= 35:\n",
    "        age_brackets['26-35'] += 1\n",
    "    elif 36 <= age <= 45:\n",
    "        age_brackets['36-45'] += 1\n",
    "    elif 46 <= age <= 55:\n",
    "        age_brackets['46-55'] += 1\n",
    "    else:\n",
    "        age_brackets['56+'] += 1\n",
    "\n",
    "print(\"\\n===== AGE DISTRIBUTION BY BRACKET =====\")\n",
    "for bracket, count in age_brackets.items():\n",
    "    percentage = (count / len(customer_ages)) * 100\n",
    "    print(f\"{bracket}: {count} customers ({percentage:.1f}%)\")\n",
    "\n",
    "# 4. Visual Analysis\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Histogram with KDE\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(customer_ages, kde=True, bins=10)\n",
    "plt.axvline(np_mean, color='r', linestyle='dashed', linewidth=1, label=f'Mean: {np_mean:.2f}')\n",
    "plt.axvline(np_median, color='g', linestyle='dashed', linewidth=1, label=f'Median: {np_median:.2f}')\n",
    "plt.axvline(np_mode, color='b', linestyle='dashed', linewidth=1, label=f'Mode: {np_mode}')\n",
    "plt.title('Customer Age Distribution')\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "# Box Plot\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(y=customer_ages)\n",
    "plt.title('Age Box Plot')\n",
    "plt.ylabel('Age (years)')\n",
    "\n",
    "# Bar chart for age brackets\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(age_brackets.keys(), age_brackets.values(), color='skyblue', edgecolor='black')\n",
    "plt.title('Customer Age Brackets')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Number of Customers')\n",
    "for i, v in enumerate(age_brackets.values()):\n",
    "    plt.text(i, v + 0.5, str(v), ha='center')\n",
    "\n",
    "# Violin plot\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.violinplot(y=customer_ages)\n",
    "plt.title('Age Distribution (Violin Plot)')\n",
    "plt.ylabel('Age (years)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('customer_age_analysis.png')\n",
    "plt.show()\n",
    "\n",
    "# 5. Additional Statistics\n",
    "print(\"\\n===== ADDITIONAL STATISTICS =====\")\n",
    "print(f\"Standard Deviation: {np.std(customer_ages, ddof=1):.2f} years\")\n",
    "print(f\"Variance: {np.var(customer_ages, ddof=1):.2f}\")\n",
    "print(f\"Skewness: {stats.skew(customer_ages):.4f}\")\n",
    "print(f\"Kurtosis: {stats.kurtosis(customer_ages):.4f}\")\n",
    "\n",
    "# 6. Percentiles and IQR\n",
    "Q1 = np.percentile(customer_ages, 25)\n",
    "Q3 = np.percentile(customer_ages, 75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(\"\\n===== PERCENTILES =====\")\n",
    "print(f\"25th Percentile (Q1): {Q1} years\")\n",
    "print(f\"50th Percentile (Median): {np_median} years\")\n",
    "print(f\"75th Percentile (Q3): {Q3} years\")\n",
    "print(f\"IQR (Interquartile Range): {IQR} years\")\n",
    "\n",
    "# 7. Outlier detection\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers = [age for age in customer_ages if age < lower_bound or age > upper_bound]\n",
    "\n",
    "print(\"\\n===== OUTLIER DETECTION =====\")\n",
    "print(f\"Lower Bound: {lower_bound:.2f} years\")\n",
    "print(f\"Upper Bound: {upper_bound:.2f} years\")\n",
    "if outliers:\n",
    "    print(f\"Outliers: {outliers}\")\n",
    "else:\n",
    "    print(\"No outliers detected\")\n",
    "\n",
    "# 8. Calculate median absolute deviation (MAD) - robust measure of variability\n",
    "mad = np.median(np.abs(customer_ages - np_median))\n",
    "print(f\"\\nMedian Absolute Deviation (MAD): {mad:.2f}\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Sample daily website visit data (30 days)\n",
    "website_visits = [\n",
    "    1254, 1380, 1432, 1198, 985, 876, 912,\n",
    "    1342, 1487, 1511, 1387, 1289, 1345, 1036,\n",
    "    987, 921, 1112, 1346, 1472, 1506,\n",
    "    1387, 1290, 1145, 1032, 876, 921, 1087,\n",
    "    1345, 1432, 1380\n",
    "]\n",
    "\n",
    "# Create dates for our sample data (last 30 days)\n",
    "today = datetime.now().date()\n",
    "dates = [(today - timedelta(days=i)) for i in range(30, 0, -1)]\n",
    "dates_str = [date.strftime('%Y-%m-%d') for date in dates]\n",
    "\n",
    "# Create DataFrame\n",
    "visits_df = pd.DataFrame({\n",
    "    'Date': dates_str,\n",
    "    'Visits': website_visits\n",
    "})\n",
    "\n",
    "# 1. Basic information\n",
    "print(\"===== WEBSITE VISITS DATA SUMMARY =====\")\n",
    "print(f\"Total days analyzed: {len(website_visits)}\")\n",
    "print(f\"Total visits: {sum(website_visits)}\")\n",
    "print(f\"Minimum daily visits: {min(website_visits)}\")\n",
    "print(f\"Maximum daily visits: {max(website_visits)}\")\n",
    "\n",
    "# 2. Mean, Median, Mode calculations\n",
    "\n",
    "# Method 1: Manual calculation\n",
    "mean_visits = sum(website_visits) / len(website_visits)\n",
    "sorted_visits = sorted(website_visits)\n",
    "n = len(sorted_visits)\n",
    "if n % 2 == 0:\n",
    "    median_visits = (sorted_visits[n//2 - 1] + sorted_visits[n//2]) / 2\n",
    "else:\n",
    "    median_visits = sorted_visits[n//2]\n",
    "\n",
    "# Finding mode manually\n",
    "visits_counter = Counter(website_visits)\n",
    "mode_visits = visits_counter.most_common(1)[0][0]\n",
    "mode_count = visits_counter.most_common(1)[0][1]\n",
    "\n",
    "print(\"\\n===== MANUAL CALCULATION =====\")\n",
    "print(f\"Mean visits per day: {mean_visits:.2f}\")\n",
    "print(f\"Median visits per day: {median_visits:.2f}\")\n",
    "print(f\"Mode visits per day: {mode_visits} (occurs {mode_count} times)\")\n",
    "\n",
    "# Method 2: Using NumPy and SciPy\n",
    "np_mean = np.mean(website_visits)\n",
    "np_median = np.median(website_visits)\n",
    "mode_result = stats.mode(website_visits)\n",
    "# Handle both older and newer versions of scipy\n",
    "try:\n",
    "    # For newer scipy versions where mode() returns scalar values when input is 1D\n",
    "    np_mode = mode_result.mode\n",
    "    np_mode_count = mode_result.count\n",
    "except (IndexError, AttributeError):\n",
    "    # For older scipy versions where mode returns arrays\n",
    "    np_mode = mode_result.mode[0]\n",
    "    np_mode_count = mode_result.count[0]\n",
    "\n",
    "print(\"\\n===== NUMPY/SCIPY CALCULATION =====\")\n",
    "print(f\"Mean visits per day: {np_mean:.2f}\")\n",
    "print(f\"Median visits per day: {np_median:.2f}\")\n",
    "print(f\"Mode visits per day: {np_mode} (occurs {np_mode_count} times)\")\n",
    "\n",
    "# Method 3: Using Pandas\n",
    "print(\"\\n===== PANDAS CALCULATION =====\")\n",
    "print(visits_df['Visits'].describe())\n",
    "print(f\"Mode: {visits_df['Visits'].mode()[0]}\")\n",
    "\n",
    "# 3. Day of week analysis (assuming our date range includes all days of week)\n",
    "# Add day of week column\n",
    "visits_df['Date'] = pd.to_datetime(visits_df['Date'])\n",
    "visits_df['DayOfWeek'] = visits_df['Date'].dt.day_name()\n",
    "\n",
    "# Calculate average visits by day of week\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_visits = visits_df.groupby('DayOfWeek')['Visits'].agg(['mean', 'median', 'count'])\n",
    "dow_visits = dow_visits.reindex(day_order)\n",
    "\n",
    "print(\"\\n===== VISITS BY DAY OF WEEK =====\")\n",
    "print(dow_visits)\n",
    "\n",
    "# 4. Visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Time series line plot\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(visits_df['Date'], visits_df['Visits'], marker='o', linestyle='-')\n",
    "plt.axhline(y=np_mean, color='r', linestyle='--', label=f'Mean: {np_mean:.2f}')\n",
    "plt.axhline(y=np_median, color='g', linestyle='--', label=f'Median: {np_median:.2f}')\n",
    "plt.title('Daily Website Visits Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(website_visits, kde=True, bins=10)\n",
    "plt.axvline(np_mean, color='r', linestyle='--', label=f'Mean: {np_mean:.2f}')\n",
    "plt.axvline(np_median, color='g', linestyle='--', label=f'Median: {np_median:.2f}')\n",
    "plt.axvline(np_mode, color='b', linestyle='--', label=f'Mode: {np_mode}')\n",
    "plt.title('Distribution of Daily Visits')\n",
    "plt.xlabel('Number of Visits')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Box plot\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(y=website_visits)\n",
    "plt.title('Daily Visits Box Plot')\n",
    "plt.ylabel('Number of Visits')\n",
    "\n",
    "# Bar chart by day of week\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.barplot(x=dow_visits.index, y=dow_visits['mean'])\n",
    "plt.title('Average Visits by Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Average Visits')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('website_visits_analysis.png')\n",
    "plt.show()\n",
    "\n",
    "# 5. Trend Analysis\n",
    "# Calculate moving average (7-day window)\n",
    "visits_df['7_Day_MA'] = visits_df['Visits'].rolling(window=7).mean()\n",
    "\n",
    "# Plot with moving average\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(visits_df['Date'], visits_df['Visits'], marker='o', linestyle='-', label='Daily Visits')\n",
    "plt.plot(visits_df['Date'], visits_df['7_Day_MA'], color='red', linewidth=2, label='7-Day Moving Average')\n",
    "plt.title('Daily Website Visits with 7-Day Moving Average')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('website_visits_trend.png')\n",
    "plt.show()\n",
    "\n",
    "# 6. Additional Statistics\n",
    "print(\"\\n===== ADDITIONAL STATISTICS =====\")\n",
    "print(f\"Standard Deviation: {np.std(website_visits, ddof=1):.2f}\")\n",
    "print(f\"Variance: {np.var(website_visits, ddof=1):.2f}\")\n",
    "print(f\"Coefficient of Variation: {(np.std(website_visits, ddof=1) / np_mean) * 100:.2f}%\")\n",
    "print(f\"Skewness: {stats.skew(website_visits):.4f}\")\n",
    "print(f\"Kurtosis: {stats.kurtosis(website_visits):.4f}\")\n",
    "\n",
    "# 7. Percentiles\n",
    "print(\"\\n===== PERCENTILES =====\")\n",
    "percentiles = [10, 25, 50, 75, 90, 95]\n",
    "for p in percentiles:\n",
    "    print(f\"{p}th Percentile: {np.percentile(website_visits, p):.1f} visits\")\n",
    "\n",
    "# 8. Outlier detection\n",
    "Q1 = np.percentile(website_visits, 25)\n",
    "Q3 = np.percentile(website_visits, 75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers = [(i, visits) for i, visits in enumerate(website_visits) if visits < lower_bound or visits > upper_bound]\n",
    "\n",
    "print(\"\\n===== OUTLIER DETECTION =====\")\n",
    "print(f\"Lower Bound: {lower_bound:.2f}\")\n",
    "print(f\"Upper Bound: {upper_bound:.2f}\")\n",
    "if outliers:\n",
    "    print(f\"Outliers detected on days: {outliers}\")\n",
    "else:\n",
    "    print(\"No outliers detected\")\n",
    "\n",
    "# 9. Weekend vs. Weekday analysis\n",
    "visits_df['IsWeekend'] = visits_df['DayOfWeek'].apply(lambda x: 1 if x in ['Saturday', 'Sunday'] else 0)\n",
    "weekday_avg = visits_df[visits_df['IsWeekend'] == 0]['Visits'].mean()\n",
    "weekend_avg = visits_df[visits_df['IsWeekend'] == 1]['Visits'].mean()\n",
    "\n",
    "print(\"\\n===== WEEKEND VS WEEKDAY =====\")\n",
    "print(f\"Average weekday visits: {weekday_avg:.2f}\")\n",
    "print(f\"Average weekend visits: {weekend_avg:.2f}\")\n",
    "print(f\"Difference: {abs(weekday_avg - weekend_avg):.2f}\")\n",
    "print(f\"Weekend traffic is {(weekend_avg/weekday_avg - 1) * 100:.2f}% {'higher' if weekend_avg > weekday_avg else 'lower'} than weekday traffic\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Set the style for our visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Create a sample product price dataset\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Generate a mix of product prices with different distributions\n",
    "# Low-priced products (e.g., consumables, accessories)\n",
    "low_prices = np.random.gamma(shape=2, scale=5, size=250)\n",
    "# Mid-priced products (e.g., regular items)\n",
    "mid_prices = np.random.normal(loc=50, scale=12, size=500)\n",
    "# High-priced products (e.g., premium items)\n",
    "high_prices = np.random.lognormal(mean=4.0, sigma=0.4, size=250)\n",
    "\n",
    "# Combine all prices\n",
    "all_prices = np.concatenate([low_prices, mid_prices, high_prices])\n",
    "\n",
    "# Create a DataFrame\n",
    "product_categories = ['Low-end'] * 250 + ['Mid-range'] * 500 + ['Premium'] * 250\n",
    "product_data = pd.DataFrame({\n",
    "    'Price': all_prices,\n",
    "    'Category': product_categories\n",
    "})\n",
    "\n",
    "# Round prices to 2 decimal places to simulate real-world pricing\n",
    "product_data['Price'] = product_data['Price'].round(2)\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"===== PRODUCT PRICE DISTRIBUTION ANALYSIS =====\")\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(product_data['Price'].describe())\n",
    "\n",
    "# Calculate additional distribution metrics\n",
    "skewness = stats.skew(product_data['Price'])\n",
    "kurtosis = stats.kurtosis(product_data['Price'])\n",
    "\n",
    "print(f\"\\nSkewness: {skewness:.4f}\")\n",
    "print(f\"Kurtosis: {kurtosis:.4f}\")\n",
    "\n",
    "# Print distribution by category\n",
    "print(\"\\nDistribution by Category:\")\n",
    "category_stats = product_data.groupby('Category')['Price'].describe()\n",
    "print(category_stats)\n",
    "\n",
    "# 1. Basic Histogram\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(product_data['Price'], bins=30, kde=True)\n",
    "plt.title('Distribution of All Product Prices')\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(product_data['Price'].mean(), color='red', linestyle='--', label=f'Mean: ${product_data[\"Price\"].mean():.2f}')\n",
    "plt.axvline(product_data['Price'].median(), color='green', linestyle='--', label=f'Median: ${product_data[\"Price\"].median():.2f}')\n",
    "plt.legend()\n",
    "\n",
    "# Format x-axis as currency\n",
    "plt.gca().xaxis.set_major_formatter(ticker.StrMethodFormatter('${x:.0f}'))\n",
    "\n",
    "# 2. Histogram with Log Scale (helpful for skewed distributions)\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(product_data['Price'], bins=30, kde=True, log_scale=True)\n",
    "plt.title('Product Price Distribution (Log Scale)')\n",
    "plt.xlabel('Price ($) - Log Scale')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Format x-axis as currency\n",
    "plt.gca().xaxis.set_major_formatter(ticker.StrMethodFormatter('${x:.0f}'))\n",
    "\n",
    "# 3. Price distribution by product category\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(x='Category', y='Price', data=product_data, palette='Set3')\n",
    "plt.title('Price Distribution by Product Category')\n",
    "plt.xlabel('Product Category')\n",
    "plt.ylabel('Price ($)')\n",
    "\n",
    "# Format y-axis as currency\n",
    "plt.gca().yaxis.set_major_formatter(ticker.StrMethodFormatter('${x:.0f}'))\n",
    "\n",
    "# 4. Violin plot by category\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.violinplot(x='Category', y='Price', data=product_data, palette='Set3', inner='quartile')\n",
    "plt.title('Violin Plot of Price by Category')\n",
    "plt.xlabel('Product Category')\n",
    "plt.ylabel('Price ($)')\n",
    "\n",
    "# Format y-axis as currency\n",
    "plt.gca().yaxis.set_major_formatter(ticker.StrMethodFormatter('${x:.0f}'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('product_price_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# 5. Create a second figure for additional distribution visualizations\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# CDF (Cumulative Distribution Function)\n",
    "plt.subplot(2, 2, 1)\n",
    "# Sort the data for CDF\n",
    "sorted_data = np.sort(product_data['Price'])\n",
    "# Calculate the proportional values of samples\n",
    "p = 1. * np.arange(len(sorted_data)) / (len(sorted_data) - 1)\n",
    "plt.plot(sorted_data, p)\n",
    "plt.title('Cumulative Distribution Function (CDF) of Prices')\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Format x-axis as currency\n",
    "plt.gca().xaxis.set_major_formatter(ticker.StrMethodFormatter('${x:.0f}'))\n",
    "\n",
    "# Kernel Density Estimation by category\n",
    "plt.subplot(2, 2, 2)\n",
    "for category in product_data['Category'].unique():\n",
    "    sns.kdeplot(product_data[product_data['Category'] == category]['Price'], \n",
    "                label=category, fill=True, alpha=0.3)\n",
    "plt.title('KDE by Product Category')\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Format x-axis as currency\n",
    "plt.gca().xaxis.set_major_formatter(ticker.StrMethodFormatter('${x:.0f}'))\n",
    "\n",
    "# Price Range Analysis\n",
    "# Create price ranges\n",
    "bins = [0, 10, 25, 50, 100, 200, float('inf')]\n",
    "labels = ['$0-10', '$10-25', '$25-50', '$50-100', '$100-200', '$200+']\n",
    "product_data['Price Range'] = pd.cut(product_data['Price'], bins=bins, labels=labels)\n",
    "\n",
    "# Count products in each price range\n",
    "price_range_counts = product_data['Price Range'].value_counts().sort_index()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "price_range_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Number of Products by Price Range')\n",
    "plt.xlabel('Price Range')\n",
    "plt.ylabel('Number of Products')\n",
    "plt.xticks(rotation=45)\n",
    "for i, v in enumerate(price_range_counts):\n",
    "    plt.text(i, v + 5, str(v), ha='center')\n",
    "\n",
    "# QQ Plot to check for normality\n",
    "plt.subplot(2, 2, 4)\n",
    "stats.probplot(product_data['Price'], plot=plt)\n",
    "plt.title('QQ Plot of Product Prices')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('product_price_distribution_additional.png')\n",
    "plt.show()\n",
    "\n",
    "# 6. Advanced Analysis\n",
    "\n",
    "# Find price percentiles\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "price_percentiles = np.percentile(product_data['Price'], percentiles)\n",
    "\n",
    "print(\"\\nPrice Percentiles:\")\n",
    "for i, p in enumerate(percentiles):\n",
    "    print(f\"{p}th Percentile: ${price_percentiles[i]:.2f}\")\n",
    "\n",
    "# Calculate the Gini coefficient to measure price inequality\n",
    "def gini(x):\n",
    "    \"\"\"Calculate the Gini coefficient of a numpy array.\"\"\"\n",
    "    # Mean absolute difference\n",
    "    mad = np.abs(np.subtract.outer(x, x)).mean()\n",
    "    # Relative mean absolute difference\n",
    "    rmad = mad / np.mean(x)\n",
    "    # Gini coefficient\n",
    "    g = 0.5 * rmad\n",
    "    return g\n",
    "\n",
    "gini_coefficient = gini(product_data['Price'].values)\n",
    "print(f\"\\nGini Coefficient (Price Inequality): {gini_coefficient:.4f}\")\n",
    "\n",
    "# Create a stacked histogram by category with percentage\n",
    "plt.figure(figsize=(12, 6))\n",
    "category_order = ['Low-end', 'Mid-range', 'Premium']\n",
    "product_data_sorted = product_data.copy()\n",
    "product_data_sorted['Price Range'] = pd.Categorical(\n",
    "    product_data_sorted['Price Range'], \n",
    "    categories=labels, \n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Create a crosstab of category and price range\n",
    "price_category_cross = pd.crosstab(\n",
    "    product_data_sorted['Category'], \n",
    "    product_data_sorted['Price Range'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "# Plot stacked bar chart\n",
    "price_category_cross.loc[category_order].plot(kind='bar', stacked=True, colormap='viridis')\n",
    "plt.title('Price Range Distribution by Product Category (%)')\n",
    "plt.xlabel('Product Category')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Price Range')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('product_price_category_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Optional: Save the distribution data to a CSV file\n",
    "product_data.to_csv('product_price_data.csv', index=False)\n",
    "\n",
    "print(\"\\nDistribution analysis complete! Visualizations and data summary saved.\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Set the visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Generate sample exam data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Create a dataset with scores from different subjects\n",
    "n_students = 200\n",
    "\n",
    "# Generate scores for different subjects with different distributions\n",
    "# Math tends to have a bimodal distribution\n",
    "math_scores = np.concatenate([\n",
    "    np.random.normal(loc=65, scale=12, size=int(n_students*0.6)),  # Lower peak\n",
    "    np.random.normal(loc=90, scale=8, size=int(n_students*0.4))    # Higher peak\n",
    "])\n",
    "\n",
    "# English often has a more normal distribution\n",
    "english_scores = np.random.normal(loc=75, scale=15, size=n_students)\n",
    "\n",
    "# Science may have a slightly skewed distribution\n",
    "science_scores = np.random.beta(a=7, b=3, size=n_students) * 100\n",
    "\n",
    "# History scores\n",
    "history_scores = np.random.normal(loc=72, scale=14, size=n_students)\n",
    "\n",
    "# Ensure all scores are within realistic bounds (0-100)\n",
    "subjects = ['Math', 'English', 'Science', 'History']\n",
    "score_arrays = [math_scores, english_scores, science_scores, history_scores]\n",
    "\n",
    "for i, scores in enumerate(score_arrays):\n",
    "    # Clip scores between 0 and 100\n",
    "    score_arrays[i] = np.clip(scores, 0, 100)\n",
    "    # Round to integers like real scores\n",
    "    score_arrays[i] = np.round(scores).astype(int)\n",
    "\n",
    "# Create a DataFrame with student IDs and scores\n",
    "student_ids = [f\"S{i+1:03d}\" for i in range(n_students)]\n",
    "\n",
    "# Create a DataFrame in \"long format\" for easier plotting with seaborn\n",
    "exam_data_long = pd.DataFrame({\n",
    "    'Student ID': np.repeat(student_ids, len(subjects)),\n",
    "    'Subject': np.tile(subjects, n_students),\n",
    "    'Score': np.concatenate([scores[:n_students] for scores in score_arrays])\n",
    "})\n",
    "\n",
    "# Also create a DataFrame in \"wide format\" for certain analyses\n",
    "exam_data_wide = pd.DataFrame({\n",
    "    'Student ID': student_ids,\n",
    "    'Math': score_arrays[0][:n_students],\n",
    "    'English': score_arrays[1][:n_students],\n",
    "    'Science': score_arrays[2][:n_students],\n",
    "    'History': score_arrays[3][:n_students]\n",
    "})\n",
    "\n",
    "# Add overall average score for each student\n",
    "exam_data_wide['Average'] = exam_data_wide[subjects].mean(axis=1)\n",
    "\n",
    "# Define grade boundaries\n",
    "def assign_grade(score):\n",
    "    if score >= 90:\n",
    "        return 'A'\n",
    "    elif score >= 80:\n",
    "        return 'B'\n",
    "    elif score >= 70:\n",
    "        return 'C'\n",
    "    elif score >= 60:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "# Add grades for each subject and overall\n",
    "for subject in subjects + ['Average']:\n",
    "    exam_data_wide[f'{subject} Grade'] = exam_data_wide[subject].apply(assign_grade)\n",
    "\n",
    "# Print basic statistics\n",
    "print(\"===== EXAM SCORE DISTRIBUTION ANALYSIS =====\")\n",
    "print(\"\\nBasic Statistics by Subject:\")\n",
    "subject_stats = exam_data_long.groupby('Subject')['Score'].describe()\n",
    "print(subject_stats)\n",
    "\n",
    "# Grade distribution\n",
    "grade_counts = {}\n",
    "for subject in subjects + ['Average']:\n",
    "    grade_counts[subject] = exam_data_wide[f'{subject} Grade'].value_counts().sort_index()\n",
    "\n",
    "print(\"\\nGrade Distribution:\")\n",
    "for subject, counts in grade_counts.items():\n",
    "    print(f\"\\n{subject}:\")\n",
    "    for grade, count in counts.items():\n",
    "        percentage = (count / n_students) * 100\n",
    "        print(f\"{grade}: {count} students ({percentage:.1f}%)\")\n",
    "\n",
    "# Calculate additional distribution metrics\n",
    "print(\"\\nDistribution Metrics by Subject:\")\n",
    "for subject in subjects:\n",
    "    subject_scores = exam_data_wide[subject]\n",
    "    skewness = stats.skew(subject_scores)\n",
    "    kurtosis = stats.kurtosis(subject_scores)\n",
    "    print(f\"\\n{subject}:\")\n",
    "    print(f\"Skewness: {skewness:.4f}\")\n",
    "    print(f\"Kurtosis: {kurtosis:.4f}\")\n",
    "    \n",
    "    # Calculate passing rate (score >= 60)\n",
    "    passing_rate = (subject_scores >= 60).mean() * 100\n",
    "    print(f\"Passing Rate: {passing_rate:.1f}%\")\n",
    "\n",
    "# 1. Histograms of scores by subject\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Use a 2x2 grid for the four subjects\n",
    "for i, subject in enumerate(subjects):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    subject_data = exam_data_wide[subject]\n",
    "    \n",
    "    # Create the histogram with KDE\n",
    "    sns.histplot(subject_data, bins=20, kde=True)\n",
    "    \n",
    "    # Add vertical lines for mean and median\n",
    "    plt.axvline(subject_data.mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {subject_data.mean():.1f}')\n",
    "    plt.axvline(subject_data.median(), color='green', linestyle='--', \n",
    "                label=f'Median: {subject_data.median():.1f}')\n",
    "    \n",
    "    # Add grade boundaries with different colors\n",
    "    grade_bounds = [60, 70, 80, 90]\n",
    "    grade_labels = ['D', 'C', 'B', 'A']\n",
    "    colors = ['#ffcccc', '#ffffcc', '#ccffcc', '#ccccff']\n",
    "    \n",
    "    # Fill areas for different grades\n",
    "    for j in range(len(grade_bounds)):\n",
    "        if j == 0:\n",
    "            plt.axvspan(0, grade_bounds[j], alpha=0.2, color='#ffcccc', label='F')\n",
    "        if j < len(grade_bounds) - 1:\n",
    "            plt.axvspan(grade_bounds[j], grade_bounds[j+1], alpha=0.2, color=colors[j+1], \n",
    "                      label=grade_labels[j])\n",
    "        else:\n",
    "            plt.axvspan(grade_bounds[j], 100, alpha=0.2, color=colors[j], \n",
    "                      label=grade_labels[j])\n",
    "    \n",
    "    plt.title(f'{subject} Score Distribution')\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Number of Students')\n",
    "    plt.xlim(0, 100)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('exam_score_distributions.png')\n",
    "plt.show()\n",
    "\n",
    "# 2. Box plots for comparing distributions across subjects\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Subject', y='Score', data=exam_data_long, palette='Set3')\n",
    "plt.title('Score Distribution Comparison Across Subjects')\n",
    "plt.xlabel('Subject')\n",
    "plt.ylabel('Score')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('exam_score_boxplots.png')\n",
    "plt.show()\n",
    "\n",
    "# 3. Violin plots for more detailed distribution comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(x='Subject', y='Score', data=exam_data_long, palette='Set3', inner='quartile')\n",
    "plt.title('Detailed Score Distribution by Subject (Violin Plot)')\n",
    "plt.xlabel('Subject')\n",
    "plt.ylabel('Score')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('exam_score_violinplots.png')\n",
    "plt.show()\n",
    "\n",
    "# 4. Grade distribution bar chart\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Prepare data for stacked bar chart\n",
    "grade_data = pd.DataFrame({subject: grade_counts[subject] for subject in subjects + ['Average']})\n",
    "grade_data = grade_data.fillna(0)\n",
    "\n",
    "# Create a stacked bar chart\n",
    "grade_data.plot(kind='bar', stacked=False, figsize=(14, 8))\n",
    "plt.title('Grade Distribution by Subject')\n",
    "plt.xlabel('Grade')\n",
    "plt.ylabel('Number of Students')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.legend(title='Subject')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('exam_grade_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# 5. Kernel Density Estimation (KDE) plot for all subjects\n",
    "plt.figure(figsize=(12, 6))\n",
    "for subject in subjects:\n",
    "    sns.kdeplot(exam_data_wide[subject], label=subject, fill=True, alpha=0.3)\n",
    "plt.title('Score Density Distribution by Subject')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.savefig('exam_score_kde.png')\n",
    "plt.show()\n",
    "\n",
    "# 6. Correlation between subjects (heatmap)\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = exam_data_wide[subjects].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Between Subject Scores')\n",
    "plt.tight_layout()\n",
    "plt.savefig('exam_score_correlation.png')\n",
    "plt.show()\n",
    "\n",
    "# 7. Cumulative distribution function (CDF)\n",
    "plt.figure(figsize=(12, 6))\n",
    "for subject in subjects:\n",
    "    # Sort the data\n",
    "    sorted_data = np.sort(exam_data_wide[subject])\n",
    "    # Calculate the proportional values of samples\n",
    "    p = 1. * np.arange(len(sorted_data)) / (len(sorted_data) - 1)\n",
    "    plt.plot(sorted_data, p, label=subject)\n",
    "\n",
    "plt.title('Cumulative Distribution of Scores by Subject')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.savefig('exam_score_cdf.png')\n",
    "plt.show()\n",
    "\n",
    "# 8. Create bins for score ranges and analyze distribution\n",
    "score_bins = [0, 20, 40, 60, 70, 80, 90, 100]\n",
    "bin_labels = ['0-20', '21-40', '41-60', '61-70', '71-80', '81-90', '91-100']\n",
    "\n",
    "for subject in subjects:\n",
    "    exam_data_wide[f'{subject} Range'] = pd.cut(\n",
    "        exam_data_wide[subject], \n",
    "        bins=score_bins, \n",
    "        labels=bin_labels,\n",
    "        include_lowest=True\n",
    "    )\n",
    "\n",
    "# Count by score range for each subject\n",
    "range_distributions = {}\n",
    "for subject in subjects:\n",
    "    range_distributions[subject] = exam_data_wide[f'{subject} Range'].value_counts().sort_index()\n",
    "\n",
    "# Plot score range distribution\n",
    "plt.figure(figsize=(14, 8))\n",
    "range_dist_df = pd.DataFrame(range_distributions)\n",
    "range_dist_df.plot(kind='bar', figsize=(14, 8))\n",
    "plt.title('Score Range Distribution by Subject')\n",
    "plt.xlabel('Score Range')\n",
    "plt.ylabel('Number of Students')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.legend(title='Subject')\n",
    "plt.tight_layout()\n",
    "plt.savefig('exam_score_ranges.png')\n",
    "plt.show()\n",
    "\n",
    "# 9. Normal probability plot (QQ plot) for each subject\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, subject in enumerate(subjects):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    stats.probplot(exam_data_wide[subject], plot=plt)\n",
    "    plt.title(f'QQ Plot for {subject} Scores')\n",
    "plt.tight_layout()\n",
    "plt.savefig('exam_score_qqplots.png')\n",
    "plt.show()\n",
    "\n",
    "# Optional: Save the exam data to CSV files\n",
    "exam_data_wide.to_csv('exam_data_wide.csv', index=False)\n",
    "exam_data_long.to_csv('exam_data_long.csv', index=False)\n",
    "\n",
    "print(\"\\nExam score distribution analysis complete! Visualizations and data summary saved.\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Set the visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Generate sample order quantity data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Create a dataset with order information\n",
    "n_orders = 1000\n",
    "start_date = datetime(2024, 1, 1)\n",
    "end_date = datetime(2024, 4, 30)\n",
    "\n",
    "# Generate random dates between start and end date\n",
    "days_range = (end_date - start_date).days\n",
    "random_days = np.random.randint(0, days_range, n_orders)\n",
    "order_dates = [start_date + timedelta(days=day) for day in random_days]\n",
    "\n",
    "# Sort dates chronologically\n",
    "order_dates.sort()\n",
    "\n",
    "# Generate product categories with different order quantity patterns\n",
    "categories = ['Electronics', 'Clothing', 'Food', 'Home Goods', 'Office Supplies']\n",
    "category_probs = [0.15, 0.25, 0.3, 0.2, 0.1]  # Probability of each category\n",
    "\n",
    "# Sample categories based on probability\n",
    "product_categories = np.random.choice(categories, n_orders, p=category_probs)\n",
    "\n",
    "# Generate order quantities with different distributions based on category\n",
    "order_quantities = []\n",
    "\n",
    "for category in product_categories:\n",
    "    if category == 'Electronics':\n",
    "        # Electronics typically have lower quantities per order\n",
    "        quantity = max(1, int(np.random.lognormal(1.1, 0.8)))\n",
    "    elif category == 'Clothing':\n",
    "        # Clothing might have medium quantities\n",
    "        quantity = max(1, int(np.random.normal(3, 2)))\n",
    "    elif category == 'Food':\n",
    "        # Food items might have higher quantities\n",
    "        quantity = max(1, int(np.random.gamma(5, 1)))\n",
    "    elif category == 'Home Goods':\n",
    "        # Home goods with medium to low quantities\n",
    "        quantity = max(1, int(np.random.poisson(2)))\n",
    "    else:  # Office Supplies\n",
    "        # Office supplies with more varied quantities\n",
    "        quantity = max(1, int(np.random.exponential(5)))\n",
    "    \n",
    "    order_quantities.append(quantity)\n",
    "\n",
    "# Create the main DataFrame\n",
    "order_data = pd.DataFrame({\n",
    "    'OrderDate': order_dates,\n",
    "    'Category': product_categories,\n",
    "    'Quantity': order_quantities\n",
    "})\n",
    "\n",
    "# Add some additional features for analysis\n",
    "order_data['Month'] = order_data['OrderDate'].dt.month_name()\n",
    "order_data['DayOfWeek'] = order_data['OrderDate'].dt.day_name()\n",
    "order_data['WeekOfYear'] = order_data['OrderDate'].dt.isocalendar().week\n",
    "\n",
    "# Print basic statistics\n",
    "print(\"===== ORDER QUANTITY DISTRIBUTION ANALYSIS =====\")\n",
    "print(\"\\nBasic Statistics for All Orders:\")\n",
    "print(order_data['Quantity'].describe())\n",
    "\n",
    "# Statistics by category\n",
    "print(\"\\nOrder Quantity Statistics by Product Category:\")\n",
    "category_stats = order_data.groupby('Category')['Quantity'].describe()\n",
    "print(category_stats)\n",
    "\n",
    "# Calculate additional distribution metrics by category\n",
    "print(\"\\nDistribution Metrics by Category:\")\n",
    "for category in categories:\n",
    "    category_qty = order_data[order_data['Category'] == category]['Quantity']\n",
    "    skewness = stats.skew(category_qty)\n",
    "    kurtosis = stats.kurtosis(category_qty)\n",
    "    print(f\"\\n{category}:\")\n",
    "    print(f\"Skewness: {skewness:.4f}\")\n",
    "    print(f\"Kurtosis: {kurtosis:.4f}\")\n",
    "    print(f\"Coefficient of Variation: {(category_qty.std() / category_qty.mean()) * 100:.2f}%\")\n",
    "\n",
    "# 1. Overall distribution of order quantities\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(order_data['Quantity'], bins=30, kde=True)\n",
    "plt.title('Distribution of Order Quantities (All Products)')\n",
    "plt.xlabel('Order Quantity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(order_data['Quantity'].mean(), color='red', linestyle='--', \n",
    "            label=f'Mean: {order_data[\"Quantity\"].mean():.2f}')\n",
    "plt.axvline(order_data['Quantity'].median(), color='green', linestyle='--', \n",
    "            label=f'Median: {order_data[\"Quantity\"].median():.2f}')\n",
    "plt.legend()\n",
    "\n",
    "# 2. Log-scaled histogram for better visibility with skewed data\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(order_data['Quantity'], bins=30, kde=True, log_scale=(False, True))\n",
    "plt.title('Order Quantity Distribution (Log Frequency Scale)')\n",
    "plt.xlabel('Order Quantity')\n",
    "plt.ylabel('Frequency (Log Scale)')\n",
    "\n",
    "# 3. Box plot by category\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(x='Category', y='Quantity', data=order_data, palette='Set3')\n",
    "plt.title('Order Quantity by Product Category')\n",
    "plt.xlabel('Product Category')\n",
    "plt.ylabel('Order Quantity')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 4. Violin plot by category\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.violinplot(x='Category', y='Quantity', data=order_data, palette='Set3', inner='quartile')\n",
    "plt.title('Detailed Order Quantity Distribution by Category')\n",
    "plt.xlabel('Product Category')\n",
    "plt.ylabel('Order Quantity')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('order_quantity_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# 5. Time-based analysis\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Resample by week for time series analysis\n",
    "weekly_orders = order_data.groupby(pd.Grouper(key='OrderDate', freq='W'))['Quantity'].agg(['count', 'sum', 'mean', 'median', 'std'])\n",
    "weekly_orders = weekly_orders.reset_index()\n",
    "\n",
    "# Plot weekly order quantities\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(weekly_orders['OrderDate'], weekly_orders['sum'], marker='o', linestyle='-')\n",
    "plt.title('Weekly Total Order Quantity')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Total Quantity')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.WeekdayLocator(interval=2))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Plot weekly average order quantity\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(weekly_orders['OrderDate'], weekly_orders['mean'], marker='o', linestyle='-', color='green')\n",
    "plt.fill_between(\n",
    "    weekly_orders['OrderDate'],\n",
    "    weekly_orders['mean'] - weekly_orders['std'],\n",
    "    weekly_orders['mean'] + weekly_orders['std'],\n",
    "    alpha=0.2,\n",
    "    color='green'\n",
    ")\n",
    "plt.title('Weekly Average Order Quantity (with Standard Deviation)')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Average Quantity')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.WeekdayLocator(interval=2))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('order_quantity_time_analysis.png')\n",
    "plt.show()\n",
    "\n",
    "# 6. Day of week distribution\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Order the days correctly\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "daily_avg = order_data.groupby('DayOfWeek')['Quantity'].mean().reindex(day_order)\n",
    "daily_count = order_data.groupby('DayOfWeek')['Quantity'].count().reindex(day_order)\n",
    "\n",
    "# Dual axis plot\n",
    "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Plot average quantity on primary y-axis\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Day of Week')\n",
    "ax1.set_ylabel('Average Order Quantity', color=color)\n",
    "ax1.bar(daily_avg.index, daily_avg.values, color=color, alpha=0.2)\n",
    "\n",
    "\n",
    "\n",
    "# 3. Data Type Validation:\n",
    "# Task 1: Validate numeric fields in a dataset to ensure they contain only numbers.\n",
    "# Task 2: Check for valid date formats in a transaction log.\n",
    "# Task 3: Validate email formats in a customer contact dataset.\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Check if 'amount' column is numeric\n",
    "is_numeric = pd.to_numeric(df['amount'], errors='coerce')\n",
    "\n",
    "# Identify invalid entries (those that became NaN)\n",
    "invalid_numeric = df[is_numeric.isna() & df['amount'].notna()]\n",
    "\n",
    "print(f\"Number of invalid numeric entries: {len(invalid_numeric)}\")\n",
    "print(\"Invalid numeric entries:\\n\", invalid_numeric)\n",
    "# Convert 'transaction_date' to datetime\n",
    "df['transaction_date_valid'] = pd.to_datetime(df['transaction_date'], errors='coerce')\n",
    "\n",
    "# Identify rows with invalid date formats\n",
    "invalid_dates = df[df['transaction_date_valid'].isna() & df['transaction_date'].notna()]\n",
    "\n",
    "print(f\"Number of invalid dates: {len(invalid_dates)}\")\n",
    "print(\"Invalid date entries:\\n\", invalid_dates)\n",
    "import re\n",
    "\n",
    "# Simple regex for email validation\n",
    "email_pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n",
    "\n",
    "# Apply regex check\n",
    "invalid_emails = df[~df['email'].astype(str).str.match(email_pattern, na=False)]\n",
    "\n",
    "print(f\"Number of invalid emails: {len(invalid_emails)}\")\n",
    "print(\"Invalid email entries:\\n\", invalid_emails[['email']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
