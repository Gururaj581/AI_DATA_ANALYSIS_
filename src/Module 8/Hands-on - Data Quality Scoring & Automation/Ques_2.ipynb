{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Data Quality Score\n",
    "**Introduction**: In this activity, you will calculate data quality scores for datasets using different metrics. You will explore examples where you assess completeness, accuracy, and consistency.\n",
    "\n",
    "### Task 1: Completeness Score\n",
    "1. Objective: Determine the percentage of non-missing values in a dataset.\n",
    "2. Steps:\n",
    "    - Load a sample dataset using Pandas.\n",
    "    - Identify the columns with missing values.\n",
    "    - Calculate the completeness score as the ratio of non-missing values to total values.\n",
    "    - E.g., a dataset with customer information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "def calculate_completeness(df):\n",
    "    \"\"\"Calculate completeness score for each column and overall dataset\"\"\"\n",
    "    completeness = df.notna().mean()\n",
    "    return {\n",
    "        'column_scores': completeness.to_dict(),\n",
    "        'overall_score': completeness.mean()\n",
    "    }\n",
    "def calculate_accuracy(df, reference_values=None):\n",
    "    \"\"\"Calculate accuracy score by comparing to reference values or checking validity\"\"\"\n",
    "    accuracy_scores = {}\n",
    "    for col in df.columns:\n",
    "        if reference_values and col in reference_values:\n",
    "            # Compare to provided reference values\n",
    "            matches = (df[col] == reference_values[col]).mean()\n",
    "        elif pd.api.types.is_numeric_dtype(df[col]):\n",
    "            # For numeric columns, check if within reasonable bounds\n",
    "            q1, q3 = df[col].quantile([0.25, 0.75])\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - 1.5*iqr\n",
    "            upper_bound = q3 + 1.5*iqr\n",
    "            valid = ((df[col] >= lower_bound) & (df[col] <= upper_bound)).mean()\n",
    "            matches = valid\n",
    "        else:\n",
    "            # For categorical, check if values are in expected set\n",
    "            expected = set(df[col].dropna().unique())\n",
    "            matches = df[col].isin(expected).mean()\n",
    "        accuracy_scores[col] = matches\n",
    "    return {\n",
    "        'column_scores': accuracy_scores,\n",
    "        'overall_score': np.mean(list(accuracy_scores.values()))\n",
    "    }\n",
    "def calculate_consistency(df):\n",
    "    \"\"\"Calculate consistency scores by checking for contradictions\"\"\"\n",
    "    consistency_scores = {}\n",
    "    # Example checks (customize based on your data logic)\n",
    "    if 'age' in df.columns and 'birth_year' in df.columns:\n",
    "        current_year = pd.Timestamp.now().year\n",
    "        calculated_age = current_year - df['birth_year']\n",
    "        age_diff = abs(calculated_age - df['age'])\n",
    "        consistency_scores['age_consistency'] = (age_diff <= 1).mean()\n",
    "    \n",
    "    if 'start_date' in df.columns and 'end_date' in df.columns:\n",
    "        date_consistent = (df['end_date'] >= df['start_date']).mean()\n",
    "        consistency_scores['date_consistency'] = date_consistent\n",
    "    \n",
    "    return {\n",
    "        'specific_checks': consistency_scores,\n",
    "        'overall_score': np.mean(list(consistency_scores.values())) if consistency_scores else 1.0\n",
    "    }\n",
    "\n",
    "def calculate_uniqueness(df):\n",
    "    \"\"\"Calculate uniqueness scores for columns\"\"\"\n",
    "    uniqueness = {}\n",
    "    for col in df.columns:\n",
    "        uniqueness[col] = df[col].nunique() / len(df[col])\n",
    "    return {\n",
    "        'column_scores': uniqueness,\n",
    "        'overall_score': np.mean(list(uniqueness.values()))\n",
    "    }\n",
    "\n",
    "def calculate_timeliness(df, date_columns=None):\n",
    "    \"\"\"Calculate timeliness scores for date columns\"\"\"\n",
    "    if date_columns is None:\n",
    "        date_columns = [col for col in df.columns if pd.api.types.is_datetime64_any_dtype(df[col])]\n",
    "    \n",
    "    timeliness = {}\n",
    "    current_time = pd.Timestamp.now()\n",
    "    \n",
    "    for col in date_columns:\n",
    "        if col + '_expected_delay' in df.columns:\n",
    "            # If we have expected delay information\n",
    "            is_timely = (current_time - df[col]) <= df[col + '_expected_delay']\n",
    "            timeliness[col] = is_timely.mean()\n",
    "        else:\n",
    "            # Default check for recent data (within 1 year)\n",
    "            is_recent = (current_time - df[col]) <= pd.Timedelta(days=365)\n",
    "            timeliness[col] = is_recent.mean()\n",
    "    \n",
    "    return {\n",
    "        'column_scores': timeliness,\n",
    "        'overall_score': np.mean(list(timeliness.values())) if timeliness else 1.0\n",
    "    }\n",
    "\n",
    "def visualize_quality_scores(scores, title=\"Data Quality Metrics\"):\n",
    "    \"\"\"Visualize quality scores\"\"\"\n",
    "    metrics = ['Completeness', 'Accuracy', 'Consistency', 'Uniqueness', 'Timeliness']\n",
    "    values = [\n",
    "        scores['completeness']['overall_score'],\n",
    "        scores['accuracy']['overall_score'],\n",
    "        scores['consistency']['overall_score'],\n",
    "        scores['uniqueness']['overall_score'],\n",
    "        scores['timeliness']['overall_score']\n",
    "    ]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    bars = plt.bar(metrics, values, color=['#4C72B0', '#55A868', '#C44E52', '#8172B2', '#CCB974'])\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1%}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Quality Score')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "def calculate_data_quality(df, reference_values=None):\n",
    "    \"\"\"Calculate comprehensive data quality scores\"\"\"\n",
    "    quality_scores = {\n",
    "        'completeness': calculate_completeness(df),\n",
    "        'accuracy': calculate_accuracy(df, reference_values),\n",
    "        'consistency': calculate_consistency(df),\n",
    "        'uniqueness': calculate_uniqueness(df),\n",
    "        'timeliness': calculate_timeliness(df)\n",
    "    }\n",
    "    \n",
    "    # Calculate overall weighted score\n",
    "    weights = {\n",
    "        'completeness': 0.3,\n",
    "        'accuracy': 0.3,\n",
    "        'consistency': 0.2,\n",
    "        'uniqueness': 0.1,\n",
    "        'timeliness': 0.1\n",
    "    }\n",
    "    \n",
    "    weighted_scores = [quality_scores[k]['overall_score'] * weights[k] for k in weights]\n",
    "    quality_scores['overall_score'] = np.sum(weighted_scores)\n",
    "    \n",
    "    return quality_scores\n",
    "\n",
    "# Example usage with synthetic customer data\n",
    "np.random.seed(42)\n",
    "n_records = 1000\n",
    "\n",
    "# Create synthetic customer data with intentional quality issues\n",
    "data = pd.DataFrame({\n",
    "    'customer_id': range(1, n_records+1),\n",
    "    'name': np.random.choice(['John', 'Jane', 'Mike', 'Sarah', 'Alex', None], n_records),\n",
    "    'age': np.random.randint(18, 80, n_records),\n",
    "    'birth_year': 2023 - np.random.randint(18, 80, n_records),\n",
    "    'email': [f\"user{i}@example.com\" if i%10!=0 else None for i in range(n_records)],\n",
    "    'join_date': pd.date_range('2018-01-01', periods=n_records, freq='D').values,\n",
    "    'last_purchase': pd.to_datetime(np.random.choice(\n",
    "        pd.date_range('2022-01-01', '2023-06-01'), n_records)),\n",
    "    'purchase_count': np.random.poisson(5, n_records),\n",
    "    'total_spent': np.random.exponential(100, n_records),\n",
    "    'segment': np.random.choice(['A', 'B', 'C', None], n_records, p=[0.4, 0.3, 0.2, 0.1])\n",
    "})\n",
    "\n",
    "\n",
    "data.loc[10:20, 'age'] = 200 \n",
    "data.loc[30:40, 'birth_year'] = 1800  \n",
    "data.loc[50:60, 'join_date'] = data.loc[50:60, 'last_purchase'] + pd.Timedelta(days=1)  # Inconsistent dates\n",
    "data.loc[70:80, 'purchase_count'] = -1  \n",
    "data.loc[90:100, 'total_spent'] = np.nan \n",
    "quality_scores = calculate_data_quality(data)\n",
    "print(\"Data Quality Scores:\")\n",
    "print(f\"Overall Quality Score: {quality_scores['overall_score']:.1%}\")\n",
    "print(\"\\nDetailed Scores:\")\n",
    "for metric in ['completeness', 'accuracy', 'consistency', 'uniqueness', 'timeliness']:\n",
    "    print(f\"{metric.capitalize()}: {quality_scores[metric]['overall_score']:.1%}\")\n",
    "visualize_quality_scores(quality_scores, \"Customer Data Quality Assessment\")\n",
    "print(\"\\nColumn Completeness Scores:\")\n",
    "for col, score in quality_scores['completeness']['column_scores'].items():\n",
    "    print(f\"{col}: {score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Accuracy Score\n",
    "\n",
    "1. Objective: Measure the accuracy of a dataset by comparing it against a reference dataset.\n",
    "2. Steps:\n",
    "    - Load the main dataset and a reference dataset.\n",
    "    - Select key columns for accuracy check.\n",
    "    - Match values from both datasets and calculate the accuracy percentage.\n",
    "    - E.g., along existing dataset with sales information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from fuzzywuzzy import fuzz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_accuracy(main_df, reference_df, key_columns, match_columns, fuzzy_match_threshold=85):\n",
    "    \"\"\"\n",
    "    Calculate accuracy scores by comparing main dataset to reference dataset\n",
    "    \n",
    "    Args:\n",
    "        main_df: Primary dataset to evaluate\n",
    "        reference_df: Ground truth reference dataset\n",
    "        key_columns: List of columns used to match records between datasets\n",
    "        match_columns: Dictionary of columns to compare {column_name: (tolerance, comparison_type)}\n",
    "            comparison_type: 'exact', 'numeric', 'date', 'fuzzy'\n",
    "        fuzzy_match_threshold: Minimum fuzzy match score (0-100)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing accuracy scores and detailed results\n",
    "    \"\"\"\n",
    "    merged = pd.merge(main_df, reference_df, \n",
    "                     on=key_columns, \n",
    "                     how='left',\n",
    "                     suffixes=('', '_reference'))\n",
    "    \n",
    "    accuracy_results = {\n",
    "        'column_scores': {},\n",
    "        'record_scores': [],\n",
    "        'overall_accuracy': None\n",
    "    }\n",
    "    for col, (tolerance, comp_type) in match_columns.items():\n",
    "        ref_col = f\"{col}_reference\"\n",
    "        \n",
    "        if comp_type == 'exact':\n",
    "            matches = (merged[col] == merged[ref_col])\n",
    "        elif comp_type == 'numeric':\n",
    "            matches = (abs(merged[col] - merged[ref_col]) <= tolerance)\n",
    "        elif comp_type == 'date':\n",
    "            date_diff = (merged[col] - merged[ref_col]).abs()\n",
    "            matches = (date_diff <= pd.Timedelta(days=tolerance))\n",
    "        elif comp_type == 'fuzzy':\n",
    "            matches = merged.apply(lambda x: fuzz.ratio(str(x[col]), str(x[ref_col])) >= fuzzy_match_threshold, axis=1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown comparison type: {comp_type}\")\n",
    "        \n",
    "        accuracy = matches.mean()\n",
    "        accuracy_results['column_scores'][col] = {\n",
    "            'accuracy': accuracy,\n",
    "            'mismatches': len(matches) - matches.sum(),\n",
    "            'comparison_type': comp_type,\n",
    "            'tolerance': tolerance\n",
    "        }\n",
    "        accuracy_results['record_scores'].append(matches.astype(int))\n",
    "    if accuracy_results['record_scores']:\n",
    "        all_matches = pd.concat(accuracy_results['record_scores'], axis=1).all(axis=1)\n",
    "        accuracy_results['overall_accuracy'] = all_matches.mean()\n",
    "    return accuracy_results\n",
    "def visualize_accuracy(results, title=\"Data Accuracy Assessment\"):\n",
    "    \"\"\"Visualize accuracy scores\"\"\"\n",
    "    if not results['column_scores']:\n",
    "        print(\"No accuracy metrics to visualize\")\n",
    "        return\n",
    "    cols = list(results['column_scores'].keys())\n",
    "    accuracies = [results['column_scores'][col]['accuracy'] for col in cols]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(cols, accuracies, color='#2ca02c')\n",
    "    plt.axhline(y=results['overall_accuracy'], color='r', linestyle='--', label='Overall Accuracy')\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1%}',\n",
    "                ha='center', va='bottom')\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "def generate_accuracy_report(results):\n",
    "    \"\"\"Generate detailed accuracy report\"\"\"\n",
    "    report = []\n",
    "    report.append(f\"\\n{'='*50}\")\n",
    "    report.append(\"DATA ACCURACY REPORT\")\n",
    "    report.append(f\"{'='*50}\\n\")\n",
    "    report.append(f\"Overall Accuracy: {results['overall_accuracy']:.1%}\\n\")\n",
    "    report.append(\"Column-Level Accuracy:\")\n",
    "    for col, metrics in results['column_scores'].items():\n",
    "        report.append(\n",
    "            f\"- {col}: {metrics['accuracy']:.1%} \"\n",
    "            f\"(Type: {metrics['comparison_type']}, \"\n",
    "            f\"Tolerance: {metrics['tolerance']}, \"\n",
    "            f\"Mismatches: {metrics['mismatches']})\"\n",
    "        )\n",
    "    return \"\\n\".join(report)\n",
    "np.random.seed(42)\n",
    "reference_data = pd.DataFrame({\n",
    "    'order_id': range(1001, 1101),\n",
    "    'customer_id': np.random.randint(5000, 6000, 100),\n",
    "    'product_id': np.random.choice(['P100', 'P200', 'P300', 'P400'], 100),\n",
    "    'order_date': pd.date_range('2023-01-01', periods=100),\n",
    "    'quantity': np.random.randint(1, 10, 100),\n",
    "    'unit_price': np.round(np.random.uniform(10, 100, 100), 2),\n",
    "    'customer_name': np.random.choice(['John Smith', 'Jane Doe', 'Robert Johnson', \n",
    "                                      'Emily Davis', 'Michael Brown'], 100),\n",
    "    'shipping_address': [f\"{num} Main St\" for num in np.random.randint(100, 999, 100)]\n",
    "})\n",
    "main_data = reference_data.copy()\n",
    "main_data.loc[10:15, 'quantity'] += 2  \n",
    "main_data.loc[20:25, 'unit_price'] *= 1.1  \n",
    "main_data.loc[30:35, 'order_date'] += pd.Timedelta(days=2) \n",
    "main_data.loc[40:45, 'customer_name'] = ['Jon Smith', 'J. Doe', 'R. Johnson', \n",
    "                                        'E. Davis', 'Mike Brown', 'J. Smith']\n",
    "main_data.loc[50:55, 'shipping_address'] = ['Main St', '100 Main Street', \n",
    "                                          '200 main st', '300 MAIN ST', \n",
    "                                          '400 Main St.', '500 mian st']\n",
    "key_columns = ['order_id', 'customer_id']\n",
    "match_columns = {\n",
    "    'product_id': (0, 'exact'),\n",
    "    'order_date': (1, 'date'), \n",
    "    'quantity': (1, 'numeric'),  \n",
    "    'unit_price': (5, 'numeric'),  \n",
    "    'customer_name': (0, 'fuzzy'), \n",
    "    'shipping_address': (0, 'fuzzy') \n",
    "}\n",
    "accuracy_results = calculate_accuracy(main_data, reference_data, \n",
    "                                    key_columns, match_columns)\n",
    "print(generate_accuracy_report(accuracy_results))\n",
    "visualize_accuracy(accuracy_results, \"Sales Data Accuracy Assessment\")\n",
    "merged = pd.merge(main_data, reference_data, \n",
    "                 on=key_columns, \n",
    "                 suffixes=('', '_reference'))\n",
    "print(\"\\nSample Mismatches:\")\n",
    "for col in match_columns:\n",
    "    mismatches = merged[merged[col] != merged[f\"{col}_reference\"]].head(2)\n",
    "    if not mismatches.empty:\n",
    "        print(f\"\\n{col} mismatches:\")\n",
    "        print(mismatches[[*key_columns, col, f\"{col}_reference\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Consistency Score\n",
    "\n",
    "1. Objective: Evaluate the consistency within a dataset for specific columns.\n",
    "2. Steps:\n",
    "    - Choose a column expected to have consistent values.\n",
    "    - Use statistical or rule-based checks to identify inconsistencies.\n",
    "    - Calculate the consistency score by the ratio of consistent to total entries.\n",
    "    - E.g., validating phone number formats in a contact list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def calculate_consistency_score(df, column_name, pattern=None):\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "\n",
    "    if pattern:\n",
    "        consistent_count = df[column_name].astype(str).str.match(pattern).sum()\n",
    "    else:\n",
    "        consistent_count = df[column_name].astype(bool).sum()\n",
    "    total_count = len(df)\n",
    "    if total_count == 0:\n",
    "        return 0.0\n",
    "    consistency_score = consistent_count / total_count\n",
    "    return consistency_score\n",
    "if __name__ == '__main__':\n",
    "    data = {'ID': [1, 2, 3, 4, 5],\n",
    "            'Phone': ['123-456-7890', '9876543210', '555-123-4567', '111222333', '']}\n",
    "    df = pd.DataFrame(data)\n",
    "    phone_number_pattern = r'^\\d{3}-\\d{3}-\\d{4}$'\n",
    "    phone_consistency_score = calculate_consistency_score(df, 'Phone', pattern=phone_number_pattern)\n",
    "    print(f\"Phone number consistency score: {phone_consistency_score:.2f}\")\n",
    "    data_no_pattern = {'ID': [1, 2, 3, 4, 5],\n",
    "                       'Country': ['USA', 'Canada', 'USA', 'UK', 'USA']}\n",
    "    df_no_pattern = pd.DataFrame(data_no_pattern)\n",
    "    country_consistency_score = calculate_consistency_score(df_no_pattern, 'Country')\n",
    "    print(f\"Country non-empty consistency score: {country_consistency_score:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
